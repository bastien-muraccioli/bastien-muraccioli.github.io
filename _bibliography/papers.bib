---
---

@inproceedings{10.1145/3490149.3505576,
author = {Venture, Gentiane and Muraccioli, Bastien and Bourguet, Marie-Luce and Urakami, Jacqueline},
title = {Can robots be good public speakers?},
year = {2022},
isbn = {9781450391474},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3490149.3505576},
doi = {10.1145/3490149.3505576},
abstract = {Our research aims at understanding if robots could be good at public speaking, what they need to achieve the level of a good public speaker and how they may surpass a human public speaker. Previous research results indicate that designing a robot speaker by mimicking some of the behaviours of a human speaker is not enough to create an effective robot speech performance. It can in fact be counter productive to strive for human-likeliness. In this paper, we describe how we programmed a toy-like, non-anthropomorphic small robot (the Anki Vector robot) to deliver a speech by extracting pose and facial expression information from the video of a human speaker and loosely retargeting this information to the robot. We also describe our experimental plans to compare Vector’s speech delivery performance with the performance of a more anthropomorphic robot (the SoftBank Pepper robot), which has been programmed to closely mimic the human speaker’s behaviour. They are compared in terms of their ability to evoke the positive affective responses necessary to spark interest, motivate the audience to listen, and engage the audience in meaningful ways.},
booktitle = {Proceedings of the Sixteenth International Conference on Tangible, Embedded, and Embodied Interaction},
articleno = {72},
numpages = {6},
keywords = {affective response, multimodal behaviour, public speaking, robot retargeting},
location = {Daejeon, Republic of Korea},
series = {TEI '22}
}

@INPROCEEDINGS{10870971,
  author={Samson, Marie and Muraccioli, Bastien and Kanehiro, Fumio},
  booktitle={2025 IEEE/SICE International Symposium on System Integration (SII)}, 
  title={Scalable, Training-Free Visual Language Robotics: a modular multi-model framework for consumer-grade GPUs}, 
  year={2025},
  volume={},
  number={},
  pages={193-198},
  keywords={Visualization;Robot kinematics;Scalability;Large language models;Pipelines;Robot control;System integration;Cognition;Object recognition;Robots},
  doi={10.1109/SII59315.2025.10870971}
  url={https://scalable-visual-language-robotics.github.io/}
}

@inproceedings{muraccioli2025control,
  author    = {Bastien Muraccioli and Mathieu Celerier and Mehdi Benallegue and Gentiane Venture},
  title     = {Demonstrating a Control Framework for Physical Human-Robot Interaction Toward Industrial Applications},
  booktitle = {Proceedings of Robotics: Science and Systems (RSS)},
  year      = {2025},
  url       = {https://industry-ready-phri.github.io/}
}